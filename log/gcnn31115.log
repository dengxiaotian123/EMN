nohup: 忽略输入
starting loading data
2018-11-17 10:09:56
finish loading data
2018-11-17 10:12:32
batch_num 25000
configurations {'data_path': '../../data/douban/data.pkl', 'word_layers_itg': 2, 'evaluate_step': 25000, 'filter_size': 3, 'filter_h': 3, 'train_steps': 125000, 'emb_train': False, 'CPU': '/cpu:0', 'embedding_file': '../../data/douban/word_embedding.pkl', 'hidden_embedding_dim': 200, 'epoch': 5, 'print_step': 2500, 'save_path': 'Gcnn_v3_test/version1/', 'word_layers_enc': 2, '_EOS_': 1, 'word_embedding_dim': 200, 'batch_size': 40, 'max_turn_num': 9, 'final_n_class': 1, 'word_layers_agg': 2, 'max_turn_len': 50, 'output_path': 'Gcnn_v3_output/version1/', 'init_model': 'Gcnn_v3_model/version1/'}
2018-11-17 10:12:34.469959: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-17 10:12:34.469976: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-17 10:12:34.469980: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-11-17 10:12:34.469983: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-17 10:12:34.469986: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-11-17 10:12:34.577682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-11-17 10:12:34.578121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:02:00.0
Total memory: 7.92GiB
Free memory: 7.83GiB
2018-11-17 10:12:34.578132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-11-17 10:12:34.578136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-11-17 10:12:34.578143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:02:00.0)
starting shuffle train data
finish building train data
2018-11-17 10:13:59.481698: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1809 get requests, put_count=1233 evicted_count=1000 eviction_rate=0.81103 and unsatisfied allocation rate=0.926479
2018-11-17 10:13:59.481726: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
2018-11-17 10:14:01.924188: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1813 get requests, put_count=1347 evicted_count=1000 eviction_rate=0.74239 and unsatisfied allocation rate=0.817981
2018-11-17 10:14:01.924240: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 193 to 212
2018-11-17 10:14:04.439591: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1814 get requests, put_count=1536 evicted_count=1000 eviction_rate=0.651042 and unsatisfied allocation rate=0.722712
2018-11-17 10:14:04.439646: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 372 to 409
2018-11-17 10:14:07.994694: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3628 get requests, put_count=3096 evicted_count=1000 eviction_rate=0.322997 and unsatisfied allocation rate=0.444046
2018-11-17 10:14:07.994722: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 871 to 958
epoch=0 step: 2500 loss 0.45028603 processed: [0.1]
epoch=0 step: 5000 loss 0.40292484 processed: [0.2]
epoch=0 step: 7500 loss 0.27016872 processed: [0.3]
epoch=0 step: 10000 loss 0.30279565 processed: [0.4]
epoch=0 step: 12500 loss 0.38451022 processed: [0.5]
epoch=0 step: 15000 loss 0.21268499 processed: [0.6]
epoch=0 step: 17500 loss 0.26317334 processed: [0.7]
epoch=0 step: 20000 loss 0.19500452 processed: [0.8]
epoch=0 step: 22500 loss 0.19164936 processed: [0.9]
epoch=0 step: 25000 loss 0.2596621 processed: [1.0]
('R2_1', 0.9256)
save evaluate_step: 1
2018-11-17 12:55:38
starting shuffle train data
finish building train data
epoch=1 step: 27500 loss 0.37629047 processed: [1.1]
epoch=1 step: 30000 loss 0.23698695 processed: [1.2]
epoch=1 step: 32500 loss 0.3912952 processed: [1.3]
epoch=1 step: 35000 loss 0.46418488 processed: [1.4]
epoch=1 step: 37500 loss 0.27818528 processed: [1.5]
epoch=1 step: 40000 loss 0.3196701 processed: [1.6]
epoch=1 step: 42500 loss 0.37142923 processed: [1.7]
epoch=1 step: 45000 loss 0.3010955 processed: [1.8]
epoch=1 step: 47500 loss 0.21854004 processed: [1.9]
epoch=1 step: 50000 loss 0.35170525 processed: [2.0]
('R2_1', 0.93256)
save evaluate_step: 2
2018-11-17 15:39:37
0.35170525
epoch=1 save model
2018-11-17 15:39:39
starting shuffle train data
finish building train data
epoch=2 step: 52500 loss 0.26640344 processed: [2.1]
epoch=2 step: 55000 loss 0.18427956 processed: [2.2]
epoch=2 step: 57500 loss 0.22215262 processed: [2.3]
epoch=2 step: 60000 loss 0.24360785 processed: [2.4]
epoch=2 step: 62500 loss 0.2922088 processed: [2.5]
epoch=2 step: 65000 loss 0.30639547 processed: [2.6]
epoch=2 step: 67500 loss 0.34840408 processed: [2.7]
epoch=2 step: 70000 loss 0.2552575 processed: [2.8]
epoch=2 step: 72500 loss 0.3089188 processed: [2.9]
epoch=2 step: 75000 loss 0.19574168 processed: [3.0]
('R2_1', 0.9312)
save evaluate_step: 3
2018-11-17 18:23:49
0.19574168
epoch=2 save model
2018-11-17 18:23:51
starting shuffle train data
finish building train data
epoch=3 step: 77500 loss 0.2785871 processed: [3.1]
epoch=3 step: 80000 loss 0.24076104 processed: [3.2]
epoch=3 step: 82500 loss 0.12132184 processed: [3.3]
epoch=3 step: 85000 loss 0.29935846 processed: [3.4]
epoch=3 step: 87500 loss 0.20768817 processed: [3.5]
epoch=3 step: 90000 loss 0.2588392 processed: [3.6]
epoch=3 step: 92500 loss 0.12732711 processed: [3.7]
epoch=3 step: 95000 loss 0.21198621 processed: [3.8]
epoch=3 step: 97500 loss 0.26389956 processed: [3.9]
epoch=3 step: 100000 loss 0.2487008 processed: [4.0]
('R2_1', 0.92728)
save evaluate_step: 4
2018-11-17 21:07:35
0.2487008
epoch=3 save model
2018-11-17 21:07:36
starting shuffle train data
finish building train data
epoch=4 step: 102500 loss 0.18123938 processed: [4.1]
epoch=4 step: 105000 loss 0.18400274 processed: [4.2]
epoch=4 step: 107500 loss 0.14279196 processed: [4.3]
epoch=4 step: 110000 loss 0.113280885 processed: [4.4]
epoch=4 step: 112500 loss 0.062765405 processed: [4.5]
epoch=4 step: 115000 loss 0.23962241 processed: [4.6]
epoch=4 step: 117500 loss 0.10911155 processed: [4.7]
epoch=4 step: 120000 loss 0.17939562 processed: [4.8]
epoch=4 step: 122500 loss 0.35261613 processed: [4.9]
epoch=4 step: 125000 loss 0.18855086 processed: [5.0]
('R2_1', 0.92544)
save evaluate_step: 5
2018-11-17 23:48:28
0.18855086
epoch=4 save model
2018-11-17 23:48:29
train time:13.6427 h
beging test starting loading data
2018-11-17 23:48:33
finish loading data
finish building test batches
2018-11-17 23:51:07
2018-11-17 23:51:07.461013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:02:00.0)
sucess init Gcnn_v3_model/version1/
total num: 664
MAP: 0.530411888246
MRR: 0.573089381335
P@1: 0.382530120482
('R10_1:', 0.22246366418053162)
('R10_2', 0.39220214190093705)
('R10_5', 0.7706779498948176)
test time:0.0477 h
