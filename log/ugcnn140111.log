nohup: 忽略输入
starting loading data
2019-01-11 20:01:52
finish loading data
2019-01-11 20:07:22
batch_num 15625
configurations {'data_path': '../../data/ubuntu/data.pkl', 'word_layers_itg': 2, 'evaluate_step': 15625, 'filter_size': 8, 'filter_h': 3, 'train_steps': 78125, 'emb_train': False, 'CPU': '/cpu:0', 'embedding_file': '../../data/ubuntu/word_embedding.pkl', 'hidden_embedding_dim': 200, 'epoch': 5, 'lr': 0.001, 'save_path': 'Gcnn_v14_test/version/', 'word_layers_enc': 2, 'print_step': 1562, '_EOS_': 28270, 'word_embedding_dim': 200, 'batch_size': 64, 'max_turn_num': 10, 'final_n_class': 1, 'word_layers_agg': 2, 'max_turn_len': 50, 'output_path': 'Gcnn_v14_output/version/', 'init_model': 'Gcnn_v14_model/version/'}
2019-01-11 20:07:50.473214: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2019-01-11 20:07:50.473229: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2019-01-11 20:07:50.473233: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2019-01-11 20:07:50.473236: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2019-01-11 20:07:50.473240: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2019-01-11 20:07:50.577203: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-11 20:07:50.577636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2019-01-11 20:07:50.577648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2019-01-11 20:07:50.577652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2019-01-11 20:07:50.577659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
starting shuffle train data
finish building train data
2019-01-11 20:09:03.844725: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2446 get requests, put_count=1457 evicted_count=1000 eviction_rate=0.686342 and unsatisfied allocation rate=0.854047
2019-01-11 20:09:03.844754: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
2019-01-11 20:09:06.469020: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 0 get requests, put_count=1019 evicted_count=1000 eviction_rate=0.981354 and unsatisfied allocation rate=0
2019-01-11 20:09:09.440826: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2448 get requests, put_count=2729 evicted_count=2000 eviction_rate=0.732869 and unsatisfied allocation rate=0.714461
2019-01-11 20:09:09.440865: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 339 to 372
2019-01-11 20:09:12.494884: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2447 get requests, put_count=3008 evicted_count=2000 eviction_rate=0.664894 and unsatisfied allocation rate=0.610135
2019-01-11 20:09:12.494913: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 596 to 655
2019-01-11 20:09:17.529614: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 4890 get requests, put_count=4641 evicted_count=1000 eviction_rate=0.215471 and unsatisfied allocation rate=0.281391
2019-01-11 20:09:17.529650: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 1400 to 1540
epoch=1 step: 1562 loss 0.3309414 processed: [0.099968] learning_rate 0.001
epoch=1 step: 3124 loss 0.20183614 processed: [0.199936] learning_rate 0.001
epoch=1 step: 4686 loss 0.4881949 processed: [0.299904] learning_rate 0.001
epoch=1 step: 6248 loss 0.21182561 processed: [0.399872] learning_rate 0.001
epoch=1 step: 7810 loss 0.43306 processed: [0.49984] learning_rate 0.001
epoch=1 step: 9372 loss 0.19726685 processed: [0.599808] learning_rate 0.001
epoch=1 step: 10934 loss 0.39064664 processed: [0.699776] learning_rate 0.001
epoch=1 step: 12496 loss 0.31835756 processed: [0.799744] learning_rate 0.001
epoch=1 step: 14058 loss 0.2717201 processed: [0.899712] learning_rate 0.001
epoch=1 step: 15620 loss 0.26923233 processed: [0.99968] learning_rate 0.001
('R10_1', 0.7661459687581255)
('R10_2', 0.8698921935316118)
('R10_5', 0.9664979898793927)
('R2_1', 0.9362761765705943)
save evaluate_step: 1
2019-01-11 23:04:52
starting shuffle train data
finish building train data
epoch=2 step: 17182 loss 0.31972075 processed: [1.099648] learning_rate 0.001
epoch=2 step: 18744 loss 0.23484759 processed: [1.199616] learning_rate 0.001
epoch=2 step: 20306 loss 0.39772967 processed: [1.299584] learning_rate 0.001
epoch=2 step: 21868 loss 0.3305258 processed: [1.399552] learning_rate 0.001
epoch=2 step: 23430 loss 0.3125909 processed: [1.49952] learning_rate 0.001
epoch=2 step: 24992 loss 0.293978 processed: [1.599488] learning_rate 0.001
epoch=2 step: 26554 loss 0.21412678 processed: [1.699456] learning_rate 0.001
epoch=2 step: 28116 loss 0.20654964 processed: [1.799424] learning_rate 0.001
epoch=2 step: 29678 loss 0.2233009 processed: [1.899392] learning_rate 0.001
epoch=2 step: 31240 loss 0.20238051 processed: [1.99936] learning_rate 0.001
('R10_1', 0.777786667200032)
('R10_2', 0.8792127527651659)
('R10_5', 0.9687381242874572)
('R2_1', 0.9396963817829069)
save evaluate_step: 2
2019-01-12 02:02:12
0.31254566
epoch=1 save model
2019-01-12 02:02:14
starting shuffle train data
finish building train data
epoch=3 step: 32802 loss 0.2948347 processed: [2.099328] learning_rate 0.00075
epoch=3 step: 34364 loss 0.15495443 processed: [2.199296] learning_rate 0.00075
epoch=3 step: 35926 loss 0.3624556 processed: [2.299264] learning_rate 0.00075
epoch=3 step: 37488 loss 0.13982037 processed: [2.399232] learning_rate 0.00075
epoch=3 step: 39050 loss 0.19991858 processed: [2.4992] learning_rate 0.00075
epoch=3 step: 40612 loss 0.21590596 processed: [2.599168] learning_rate 0.00075
epoch=3 step: 42174 loss 0.22733146 processed: [2.699136] learning_rate 0.00075
epoch=3 step: 43736 loss 0.18356141 processed: [2.799104] learning_rate 0.00075
epoch=3 step: 45298 loss 0.18866336 processed: [2.899072] learning_rate 0.00075
epoch=3 step: 46860 loss 0.2536686 processed: [2.99904] learning_rate 0.00075
('R10_1', 0.7761465687941277)
('R10_2', 0.879812788767326)
('R10_5', 0.9695581734904094)
('R2_1', 0.9402964177850671)
save evaluate_step: 3
2019-01-12 04:58:41
0.2248904
epoch=2 save model
2019-01-12 04:58:44
starting shuffle train data
finish building train data
epoch=4 step: 48422 loss 0.18909597 processed: [3.099008] learning_rate 0.00075
epoch=4 step: 49984 loss 0.10799141 processed: [3.198976] learning_rate 0.00075
epoch=4 step: 51546 loss 0.2399022 processed: [3.298944] learning_rate 0.00075
epoch=4 step: 53108 loss 0.21095173 processed: [3.398912] learning_rate 0.00075
epoch=4 step: 54670 loss 0.2418627 processed: [3.49888] learning_rate 0.00075
epoch=4 step: 56232 loss 0.14533702 processed: [3.598848] learning_rate 0.00075
epoch=4 step: 57794 loss 0.2723093 processed: [3.698816] learning_rate 0.00075
epoch=4 step: 59356 loss 0.19735949 processed: [3.798784] learning_rate 0.00075
epoch=4 step: 60918 loss 0.17249668 processed: [3.898752] learning_rate 0.00075
epoch=4 step: 62480 loss 0.15611187 processed: [3.99872] learning_rate 0.00075
('R10_1', 0.7740864451867112)
('R10_2', 0.8773126387583255)
('R10_5', 0.9686581194871692)
('R2_1', 0.9391963517811068)
save evaluate_step: 4
2019-01-12 07:55:04
0.24077198
epoch=3 save model
2019-01-12 07:55:08
starting shuffle train data
finish building train data
epoch=5 step: 64042 loss 0.060828537 processed: [4.098688] learning_rate 0.000375
epoch=5 step: 65604 loss 0.20794225 processed: [4.198656] learning_rate 0.000375
epoch=5 step: 67166 loss 0.36836874 processed: [4.298624] learning_rate 0.000375
epoch=5 step: 68728 loss 0.2860427 processed: [4.398592] learning_rate 0.000375
epoch=5 step: 70290 loss 0.20542082 processed: [4.49856] learning_rate 0.000375
