nohup: 忽略输入
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
starting loading data
2018-11-07 22:23:53
finish loading data
2018-11-07 22:29:37
batch_num 12500
configurations {'data_path': '../../data/ubuntu/data.pkl', 'max_turn_num': 10, 'evaluate_step': 12500, 'filter_size': 2, 'filter_h': 3, 'train_steps': 75000, 'emb_train': False, 'CPU': '/cpu:0', 'embedding_file': '../../data/ubuntu/word_embedding.pkl', 'hidden_embedding_dim': 200, 'epoch': 6, 'print_step': 1250, 'save_path': 'Gcnn_v1_test/version1/', 'word_layers_enc': 1, '_EOS_': 28270, 'word_embedding_dim': 200, 'batch_size': 80, 'final_n_class': 1, 'word_layers_agg': 2, 'max_turn_len': 50, 'output_path': 'Gcnn_v1_output/version1/', 'init_model': 'Gcnn_v1_model/version1/'}
2018-11-07 22:30:05.334002: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-07 22:30:05.334019: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-07 22:30:05.334022: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-11-07 22:30:05.334025: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-07 22:30:05.334028: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-11-07 22:30:05.456206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-11-07 22:30:05.456639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:02:00.0
Total memory: 7.92GiB
Free memory: 7.83GiB
2018-11-07 22:30:05.456650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-11-07 22:30:05.456654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-11-07 22:30:05.456660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:02:00.0)
starting shuffle train data
finish building train data
2018-11-07 22:31:27.191905: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.79GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-11-07 22:31:27.292988: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2008 get requests, put_count=1468 evicted_count=1000 eviction_rate=0.681199 and unsatisfied allocation rate=0.816733
2018-11-07 22:31:27.293011: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
2018-11-07 22:31:32.007219: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2010 get requests, put_count=2579 evicted_count=2000 eviction_rate=0.775494 and unsatisfied allocation rate=0.720398
2018-11-07 22:31:32.007257: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 193 to 212
2018-11-07 22:31:36.973456: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 0 get requests, put_count=1037 evicted_count=1000 eviction_rate=0.96432 and unsatisfied allocation rate=0
2018-11-07 22:31:44.413643: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2009 get requests, put_count=2451 evicted_count=1000 eviction_rate=0.407997 and unsatisfied allocation rate=0.321055
2018-11-07 22:31:44.413682: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 958 to 1053
epoch=0 step: 1250 loss 0.37126818 processed: [0.1]
epoch=0 step: 2500 loss 0.30824646 processed: [0.2]
epoch=0 step: 3750 loss 0.24691021 processed: [0.3]
epoch=0 step: 5000 loss 0.3122688 processed: [0.4]
epoch=0 step: 6250 loss 0.31115833 processed: [0.5]
epoch=0 step: 7500 loss 0.34441978 processed: [0.6]
epoch=0 step: 8750 loss 0.35624713 processed: [0.7]
epoch=0 step: 10000 loss 0.29895243 processed: [0.8]
epoch=0 step: 11250 loss 0.290328 processed: [0.9]
epoch=0 step: 12500 loss 0.3375308 processed: [1.0]
('R10_1', 0.7494)
('R2_1', 0.93174)
save evaluate_step: 1
2018-11-08 01:50:16
starting shuffle train data
finish building train data
epoch=1 step: 13750 loss 0.20969932 processed: [1.1]
epoch=1 step: 15000 loss 0.22296561 processed: [1.2]
epoch=1 step: 16250 loss 0.19300057 processed: [1.3]
epoch=1 step: 17500 loss 0.26119775 processed: [1.4]
epoch=1 step: 18750 loss 0.24122736 processed: [1.5]
epoch=1 step: 20000 loss 0.2814716 processed: [1.6]
epoch=1 step: 21250 loss 0.26865587 processed: [1.7]
epoch=1 step: 22500 loss 0.30794224 processed: [1.8]
epoch=1 step: 23750 loss 0.3381505 processed: [1.9]
epoch=1 step: 25000 loss 0.3051925 processed: [2.0]
('R10_1', 0.76902)
('R2_1', 0.93898)
save evaluate_step: 2
2018-11-08 05:10:12
0.3051925
epoch=2 save model
2018-11-08 05:10:23
starting shuffle train data
finish building train data
epoch=2 step: 26250 loss 0.18899958 processed: [2.1]
epoch=2 step: 27500 loss 0.36307657 processed: [2.2]
epoch=2 step: 28750 loss 0.31074104 processed: [2.3]
epoch=2 step: 30000 loss 0.25630817 processed: [2.4]
epoch=2 step: 31250 loss 0.3769071 processed: [2.5]
epoch=2 step: 32500 loss 0.39308426 processed: [2.6]
epoch=2 step: 33750 loss 0.26736867 processed: [2.7]
epoch=2 step: 35000 loss 0.21753246 processed: [2.8]
epoch=2 step: 36250 loss 0.31569713 processed: [2.9]
epoch=2 step: 37500 loss 0.20475607 processed: [3.0]
('R10_1', 0.76768)
('R2_1', 0.93818)
save evaluate_step: 3
2018-11-08 08:30:03
0.20475607
epoch=3 save model
2018-11-08 08:30:04
starting shuffle train data
finish building train data
epoch=3 step: 38750 loss 0.26767763 processed: [3.1]
epoch=3 step: 40000 loss 0.27803105 processed: [3.2]
epoch=3 step: 41250 loss 0.42354965 processed: [3.3]
