nohup: 忽略输入
self.rnn_units 200
v [None, 500]
v [None, 500]
v [None, 500]
v [None, 500]
v [None, 500]
v [None, 500]
v [None, 500]
v [None, 500]
v [None, 500]
v [None, 500]
starting loading data
2019-01-13 11:25:19
finish loading data
2019-01-13 11:30:43
batch_num 15625
configurations {'data_path': '../../data/ubuntu/data.pkl', 'word_layers_itg': 3, 'evaluate_step': 15625, 'filter_size': 4, 'filter_h': 3, 'train_steps': 78125, 'emb_train': False, 'CPU': '/cpu:0', 'embedding_file': '../../data/ubuntu/word_embedding.pkl', 'hidden_embedding_dim': 200, 'epoch': 5, 'lr': 0.001, 'save_path': 'Gcnn_v14_test/version/', 'word_layers_enc': 3, 'print_step': 1562, '_EOS_': 28270, 'word_embedding_dim': 200, 'batch_size': 64, 'max_turn_num': 10, 'final_n_class': 1, 'word_layers_agg': 3, 'max_turn_len': 50, 'output_path': 'Gcnn_v14_output/version/', 'init_model': 'Gcnn_v14_model/version/'}
2019-01-13 11:31:10.590122: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2019-01-13 11:31:10.590139: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2019-01-13 11:31:10.590143: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2019-01-13 11:31:10.590146: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2019-01-13 11:31:10.590150: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2019-01-13 11:31:10.694990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-01-13 11:31:10.695423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.80GiB
2019-01-13 11:31:10.695435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2019-01-13 11:31:10.695439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2019-01-13 11:31:10.695446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
starting shuffle train data
finish building train data
2019-01-13 11:32:24.316638: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2972 get requests, put_count=1455 evicted_count=1000 eviction_rate=0.687285 and unsatisfied allocation rate=0.880552
2019-01-13 11:32:24.316665: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
2019-01-13 11:32:26.811388: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 8 get requests, put_count=1021 evicted_count=1000 eviction_rate=0.979432 and unsatisfied allocation rate=0.125
2019-01-13 11:32:26.811419: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 160 to 176
2019-01-13 11:32:29.222386: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 0 get requests, put_count=1023 evicted_count=1000 eviction_rate=0.977517 and unsatisfied allocation rate=0
2019-01-13 11:32:31.887644: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 0 get requests, put_count=2033 evicted_count=2000 eviction_rate=0.983768 and unsatisfied allocation rate=0
2019-01-13 11:32:34.605213: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 0 get requests, put_count=1054 evicted_count=1000 eviction_rate=0.948767 and unsatisfied allocation rate=0
2019-01-13 11:32:38.154885: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2971 get requests, put_count=2400 evicted_count=1000 eviction_rate=0.416667 and unsatisfied allocation rate=0.558061
2019-01-13 11:32:38.154917: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 958 to 1053
2019-01-13 11:32:43.922194: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2975 get requests, put_count=3594 evicted_count=1000 eviction_rate=0.278242 and unsatisfied allocation rate=0.190588
2019-01-13 11:32:43.922223: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 2049 to 2253
epoch=1 step: 1562 loss 0.27556902 processed: [0.099968] gs 1562 learning_rate 0.0008847359
epoch=1 step: 3124 loss 0.41689375 processed: [0.199936] gs 3124 learning_rate 0.00078275765
epoch=1 step: 4686 loss 0.20676787 processed: [0.299904] gs 4686 learning_rate 0.0006925339
epoch=1 step: 6248 loss 0.3627808 processed: [0.399872] gs 6248 learning_rate 0.0006127096
epoch=1 step: 7810 loss 0.30951497 processed: [0.49984] gs 7810 learning_rate 0.0005420862
epoch=1 step: 9372 loss 0.37093478 processed: [0.599808] gs 9372 learning_rate 0.0004796032
epoch=1 step: 10934 loss 0.31832117 processed: [0.699776] gs 10934 learning_rate 0.00042432215
epoch=1 step: 12496 loss 0.34831974 processed: [0.799744] gs 12496 learning_rate 0.00037541304
epoch=1 step: 14058 loss 0.36634752 processed: [0.899712] gs 14058 learning_rate 0.00031885577
epoch=1 step: 15620 loss 0.34232783 processed: [0.99968] gs 15620 learning_rate 0.00028210317
('R10_1', 0.7706062363741825)
('R10_2', 0.8736724203452207)
('R10_5', 0.9682780966858011)
('R2_1', 0.9384963097785867)
save evaluate_step: 1
2019-01-13 15:00:54
starting shuffle train data
finish building train data
epoch=2 step: 17182 loss 0.25240615 processed: [1.099648] gs 17182 learning_rate 0.0002495868
epoch=2 step: 18744 loss 0.24381913 processed: [1.199616] gs 18744 learning_rate 0.00022081842
epoch=2 step: 20306 loss 0.14375502 processed: [1.299584] gs 20306 learning_rate 0.00019536598
epoch=2 step: 21868 loss 0.23518701 processed: [1.399552] gs 21868 learning_rate 0.00017284731
epoch=2 step: 23430 loss 0.15577143 processed: [1.49952] gs 23430 learning_rate 0.00015292423
epoch=2 step: 24992 loss 0.23789352 processed: [1.599488] gs 24992 learning_rate 0.00013529755
epoch=2 step: 26554 loss 0.16388655 processed: [1.699456] gs 26554 learning_rate 0.0001149145
epoch=2 step: 28116 loss 0.24532013 processed: [1.799424] gs 28116 learning_rate 0.000101669
epoch=2 step: 29678 loss 0.27039072 processed: [1.899392] gs 29678 learning_rate 8.995021e-05
epoch=2 step: 31240 loss 0.3581498 processed: [1.99936] gs 31240 learning_rate 7.958218e-05
('R10_1', 0.782426945616737)
('R10_2', 0.8837930275816549)
('R10_5', 0.9714382862971779)
('R2_1', 0.9437366241974519)
save evaluate_step: 2
2019-01-13 18:30:39
0.29565865
epoch=1 save model
2019-01-13 18:30:43
starting shuffle train data
finish building train data
epoch=3 step: 32802 loss 0.18425173 processed: [2.099328] gs 32802 learning_rate 7.0409216e-05
epoch=3 step: 34364 loss 0.28154695 processed: [2.199296] gs 34364 learning_rate 6.229357e-05
epoch=3 step: 35926 loss 0.24003536 processed: [2.299264] gs 35926 learning_rate 5.5113356e-05
epoch=3 step: 37488 loss 0.21365893 processed: [2.399232] gs 37488 learning_rate 4.8760765e-05
epoch=3 step: 39050 loss 0.26308176 processed: [2.4992] gs 39050 learning_rate 4.1414787e-05
epoch=3 step: 40612 loss 0.16530737 processed: [2.599168] gs 40612 learning_rate 3.6641148e-05
epoch=3 step: 42174 loss 0.23182553 processed: [2.699136] gs 42174 learning_rate 3.2417745e-05
epoch=3 step: 43736 loss 0.23325285 processed: [2.799104] gs 43736 learning_rate 2.8681141e-05
epoch=3 step: 45298 loss 0.25805646 processed: [2.899072] gs 45298 learning_rate 2.5375239e-05
epoch=3 step: 46860 loss 0.20776857 processed: [2.99904] gs 46860 learning_rate 2.2450386e-05
('R10_1', 0.7818269096145769)
('R10_2', 0.8837530251815109)
('R10_5', 0.9710182610956657)
('R2_1', 0.9442966577994679)
save evaluate_step: 3
2019-01-13 21:59:51
0.30225435
epoch=2 save model
2019-01-13 21:59:55
starting shuffle train data
finish building train data
epoch=4 step: 48422 loss 0.4527992 processed: [3.099008] gs 48422 learning_rate 1.9862662e-05
epoch=4 step: 49984 loss 0.27735907 processed: [3.198976] gs 49984 learning_rate 1.7573211e-05
epoch=4 step: 51546 loss 0.46595067 processed: [3.298944] gs 51546 learning_rate 1.4925744e-05
epoch=4 step: 53108 loss 0.3961578 processed: [3.398912] gs 53108 learning_rate 1.3205343e-05
epoch=4 step: 54670 loss 0.18953636 processed: [3.49888] gs 54670 learning_rate 1.1683241e-05
