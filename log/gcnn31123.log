nohup: 忽略输入
starting loading data
2018-11-22 23:27:05
finish loading data
2018-11-22 23:29:43
batch_num 15625
configurations {'keep_prob': 0.8, 'data_path': '../../data/douban/data.pkl', 'word_layers_itg': 2, 'evaluate_step': 15625, 'filter_size': 2, 'filter_h': 3, 'hidden_embedding_dim': 200, 'emb_train': False, 'embedding_file': '../../data/douban/word_embedding.pkl', 'CPU': '/cpu:0', 'epoch': 11, 'lr': 0.001, 'save_path': 'Gcnn_v3_test/version_1/', 'word_layers_enc': 2, 'print_step': 1562, '_EOS_': 1, 'word_embedding_dim': 200, 'batch_size': 64, 'max_turn_num': 9, 'final_n_class': 1, 'word_layers_agg': 2, 'max_turn_len': 50, 'train_steps': 171875, 'output_path': 'Gcnn_v3_output/version_1/', 'init_model': 'Gcnn_v3_model/version_1/'}
2018-11-22 23:29:43.374020: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-22 23:29:43.374039: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-22 23:29:43.374043: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-11-22 23:29:43.374046: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-22 23:29:43.374049: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-11-22 23:29:43.643579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-11-22 23:29:43.644016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.79GiB
2018-11-22 23:29:43.644028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-11-22 23:29:43.644032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-11-22 23:29:43.644038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
starting shuffle train data
finish building train data
2018-11-22 23:31:11.371486: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1815 get requests, put_count=1236 evicted_count=1000 eviction_rate=0.809061 and unsatisfied allocation rate=0.925069
2018-11-22 23:31:11.371514: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
2018-11-22 23:31:14.437213: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1819 get requests, put_count=1350 evicted_count=1000 eviction_rate=0.740741 and unsatisfied allocation rate=0.816932
2018-11-22 23:31:14.437245: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 193 to 212
2018-11-22 23:31:17.478824: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1819 get requests, put_count=1542 evicted_count=1000 eviction_rate=0.648508 and unsatisfied allocation rate=0.720176
2018-11-22 23:31:17.478855: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 372 to 409
2018-11-22 23:31:21.820384: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3636 get requests, put_count=3097 evicted_count=1000 eviction_rate=0.322893 and unsatisfied allocation rate=0.444994
2018-11-22 23:31:21.820415: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 871 to 958
epoch=0 step: 1562 loss 0.46408367 processed: [0.099968]
epoch=0 step: 3124 loss 0.4234453 processed: [0.199936]
epoch=0 step: 4686 loss 0.3682394 processed: [0.299904]
epoch=0 step: 6248 loss 0.38761833 processed: [0.399872]
epoch=0 step: 7810 loss 0.43724412 processed: [0.49984]
epoch=0 step: 9372 loss 0.415829 processed: [0.599808]
epoch=0 step: 10934 loss 0.26661888 processed: [0.699776]
epoch=0 step: 12496 loss 0.29040435 processed: [0.799744]
epoch=0 step: 14058 loss 0.3835497 processed: [0.899712]
epoch=0 step: 15620 loss 0.39215195 processed: [0.99968]
total num: 665
MAP: 0.535021555921
MRR: 0.579086406492
P@1: 0.392481203008
('R10_1:', 0.23161355770378322)
('R10_2', 0.40941520467836234)
('R10_5', 0.7399182480009551)
('ave:', 0.4812560293007018)
save evaluate_step: 1
2018-11-23 01:29:54
learning rate: 0.001
starting shuffle train data
finish building train data
epoch=1 step: 17182 loss 0.36113536 processed: [1.099648]
epoch=1 step: 18744 loss 0.35888913 processed: [1.199616]
epoch=1 step: 20306 loss 0.20141007 processed: [1.299584]
epoch=1 step: 21868 loss 0.33126798 processed: [1.399552]
epoch=1 step: 23430 loss 0.41181815 processed: [1.49952]
epoch=1 step: 24992 loss 0.22595724 processed: [1.599488]
epoch=1 step: 26554 loss 0.3057333 processed: [1.699456]
epoch=1 step: 28116 loss 0.19388506 processed: [1.799424]
epoch=1 step: 29678 loss 0.21652251 processed: [1.899392]
epoch=1 step: 31240 loss 0.29343107 processed: [1.99936]
total num: 665
MAP: 0.548444833503
MRR: 0.592859529777
P@1: 0.404511278195
('R10_1:', 0.23796873135218993)
('R10_2', 0.4245637904284518)
('R10_5', 0.7767370807972316)
('ave:', 0.4975142073421773)
save evaluate_step: 2
2018-11-23 03:29:05
learning rate: 0.001
0.30788887
epoch=1 save model
2018-11-23 03:29:06
starting shuffle train data
finish building train data
epoch=2 step: 32802 loss 0.2417714 processed: [2.099328]
epoch=2 step: 34364 loss 0.21343419 processed: [2.199296]
epoch=2 step: 35926 loss 0.25097418 processed: [2.299264]
epoch=2 step: 37488 loss 0.21705177 processed: [2.399232]
epoch=2 step: 39050 loss 0.27685007 processed: [2.4992]
epoch=2 step: 40612 loss 0.28848556 processed: [2.599168]
epoch=2 step: 42174 loss 0.3452739 processed: [2.699136]
epoch=2 step: 43736 loss 0.28756544 processed: [2.799104]
epoch=2 step: 45298 loss 0.30739298 processed: [2.899072]
epoch=2 step: 46860 loss 0.27599064 processed: [2.99904]
total num: 665
MAP: 0.54127075886
MRR: 0.586138560687
P@1: 0.403007518797
('R10_1:', 0.24060031029955836)
('R10_2', 0.40695906432748513)
('R10_5', 0.7616242988423441)
('ave:', 0.4899334186357173)
save evaluate_step: 3
2018-11-23 05:27:56
learning rate: 0.00075
0.3006394
epoch=2 save model
2018-11-23 05:27:57
starting shuffle train data
finish building train data
epoch=3 step: 48422 loss 0.16518573 processed: [3.099008]
epoch=3 step: 49984 loss 0.16723654 processed: [3.198976]
epoch=3 step: 51546 loss 0.18611383 processed: [3.298944]
epoch=3 step: 53108 loss 0.10903075 processed: [3.398912]
epoch=3 step: 54670 loss 0.21985087 processed: [3.49888]
epoch=3 step: 56232 loss 0.338282 processed: [3.598848]
epoch=3 step: 57794 loss 0.25276417 processed: [3.698816]
epoch=3 step: 59356 loss 0.2850206 processed: [3.798784]
epoch=3 step: 60918 loss 0.24597909 processed: [3.898752]
epoch=3 step: 62480 loss 0.24870956 processed: [3.99872]
total num: 665
MAP: 0.542780703649
MRR: 0.587582647094
P@1: 0.403007518797
('R10_1:', 0.23679078649003452)
('R10_2', 0.4052321279388947)
('R10_5', 0.7689783983768949)
('ave:', 0.49072869705758443)
save evaluate_step: 4
2018-11-23 07:26:43
learning rate: 0.00075
0.19381118
epoch=3 save model
2018-11-23 07:26:45
starting shuffle train data
finish building train data
epoch=4 step: 64042 loss 0.085322455 processed: [4.098688]
epoch=4 step: 65604 loss 0.08944285 processed: [4.198656]
epoch=4 step: 67166 loss 0.1426424 processed: [4.298624]
epoch=4 step: 68728 loss 0.1766259 processed: [4.398592]
epoch=4 step: 70290 loss 0.23557636 processed: [4.49856]
epoch=4 step: 71852 loss 0.14580843 processed: [4.598528]
epoch=4 step: 73414 loss 0.22494416 processed: [4.698496]
epoch=4 step: 74976 loss 0.100010276 processed: [4.798464]
epoch=4 step: 76538 loss 0.15543094 processed: [4.898432]
epoch=4 step: 78100 loss 0.12615468 processed: [4.9984]
total num: 665
MAP: 0.538086610138
MRR: 0.582184628237
P@1: 0.386466165414
('R10_1:', 0.22804391932211476)
('R10_2', 0.41432748538011677)
('R10_5', 0.7751330707721686)
('ave:', 0.4873736465439231)
save evaluate_step: 5
2018-11-23 09:25:29
learning rate: 0.000375
0.36915734
epoch=4 save model
2018-11-23 09:25:30
starting shuffle train data
finish building train data
epoch=5 step: 79662 loss 0.16896546 processed: [5.098368]
epoch=5 step: 81224 loss 0.10875916 processed: [5.198336]
epoch=5 step: 82786 loss 0.15585697 processed: [5.298304]
epoch=5 step: 84348 loss 0.06777661 processed: [5.398272]
epoch=5 step: 85910 loss 0.11857541 processed: [5.49824]
epoch=5 step: 87472 loss 0.055493265 processed: [5.598208]
epoch=5 step: 89034 loss 0.040778466 processed: [5.698176]
epoch=5 step: 90596 loss 0.15952419 processed: [5.798144]
epoch=5 step: 92158 loss 0.18757722 processed: [5.898112]
epoch=5 step: 93720 loss 0.21392581 processed: [5.99808]
total num: 665
MAP: 0.526333102219
MRR: 0.566302661415
P@1: 0.36992481203
('R10_1:', 0.21621434538727768)
('R10_2', 0.38308867406611774)
('R10_5', 0.7721470342522977)
('ave:', 0.4723351048950164)
save evaluate_step: 6
2018-11-23 11:24:23
learning rate: 0.000375
0.07615954
epoch=5 save model
2018-11-23 11:24:24
starting shuffle train data
finish building train data
epoch=6 step: 95282 loss 0.05062709 processed: [6.098048]
epoch=6 step: 96844 loss 0.060999982 processed: [6.198016]
epoch=6 step: 98406 loss 0.028988035 processed: [6.297984]
epoch=6 step: 99968 loss 0.11997293 processed: [6.397952]
epoch=6 step: 101530 loss 0.09293322 processed: [6.49792]
epoch=6 step: 103092 loss 0.09258705 processed: [6.597888]
epoch=6 step: 104654 loss 0.05312579 processed: [6.697856]
epoch=6 step: 106216 loss 0.065153934 processed: [6.797824]
epoch=6 step: 107778 loss 0.049871802 processed: [6.897792]
epoch=6 step: 109340 loss 0.085010536 processed: [6.99776]
total num: 665
MAP: 0.532476826751
MRR: 0.575387277718
P@1: 0.38045112782
('R10_1:', 0.2210765007757489)
('R10_2', 0.4003067191788997)
('R10_5', 0.774979114452799)
('ave:', 0.48077959444940127)
save evaluate_step: 7
2018-11-23 13:23:29
learning rate: 0.0001875
0.032729216
epoch=6 save model
2018-11-23 13:23:30
starting shuffle train data
finish building train data
epoch=7 step: 110902 loss 0.08481184 processed: [7.097728]
epoch=7 step: 112464 loss 0.011688132 processed: [7.197696]
epoch=7 step: 114026 loss 0.0559102 processed: [7.297664]
epoch=7 step: 115588 loss 0.03819945 processed: [7.397632]
epoch=7 step: 117150 loss 0.014495999 processed: [7.4976]
epoch=7 step: 118712 loss 0.06762673 processed: [7.597568]
epoch=7 step: 120274 loss 0.04788389 processed: [7.697536]
epoch=7 step: 121836 loss 0.040842183 processed: [7.797504]
epoch=7 step: 123398 loss 0.01543532 processed: [7.897472]
epoch=7 step: 124960 loss 0.026242893 processed: [7.99744]
total num: 665
MAP: 0.533203476141
MRR: 0.575501253133
P@1: 0.381954887218
('R10_1:', 0.22716672633965865)
('R10_2', 0.40093328559493957)
('R10_5', 0.7653335720253016)
('ave:', 0.480682200075333)
save evaluate_step: 8
2018-11-23 15:23:27
learning rate: 0.0001875
0.17171906
epoch=7 save model
2018-11-23 15:23:29
starting shuffle train data
finish building train data
epoch=8 step: 126522 loss 0.06357722 processed: [8.097408]
epoch=8 step: 128084 loss 0.058829006 processed: [8.197376]
epoch=8 step: 129646 loss 0.014342749 processed: [8.297344]
epoch=8 step: 131208 loss 0.071607634 processed: [8.397312]
epoch=8 step: 132770 loss 0.029268626 processed: [8.49728]
epoch=8 step: 134332 loss 0.010889343 processed: [8.597248]
epoch=8 step: 135894 loss 0.03157157 processed: [8.697216]
epoch=8 step: 137456 loss 0.011913019 processed: [8.797184]
epoch=8 step: 139018 loss 0.028393354 processed: [8.897152]
epoch=8 step: 140580 loss 0.03128478 processed: [8.99712]
total num: 665
MAP: 0.532414303664
MRR: 0.576261487051
P@1: 0.383458646617
('R10_1:', 0.22814416994868117)
('R10_2', 0.398780284043442)
('R10_5', 0.7651581334288104)
('ave:', 0.4807028374586628)
save evaluate_step: 9
2018-11-23 17:23:43
learning rate: 9.375e-05
0.034070183
epoch=8 save model
2018-11-23 17:23:45
starting shuffle train data
finish building train data
epoch=9 step: 142142 loss 0.016208062 processed: [9.097088]
epoch=9 step: 143704 loss 0.027766602 processed: [9.197056]
epoch=9 step: 145266 loss 0.022336831 processed: [9.297024]
epoch=9 step: 146828 loss 0.04159749 processed: [9.396992]
epoch=9 step: 148390 loss 0.03591023 processed: [9.49696]
epoch=9 step: 149952 loss 0.014892107 processed: [9.596928]
epoch=9 step: 151514 loss 0.011457623 processed: [9.696896]
epoch=9 step: 153076 loss 0.049427226 processed: [9.796864]
epoch=9 step: 154638 loss 0.033197038 processed: [9.896832]
epoch=9 step: 156200 loss 0.0129577285 processed: [9.9968]
total num: 665
MAP: 0.530864088841
MRR: 0.576226279986
P@1: 0.381954887218
('R10_1:', 0.2267657238333929)
('R10_2', 0.39494569757727666)
('R10_5', 0.7643561284162791)
('ave:', 0.47918546764524034)
save evaluate_step: 10
2018-11-23 19:23:42
learning rate: 9.375e-05
0.019971203
epoch=9 save model
2018-11-23 19:23:43
starting shuffle train data
finish building train data
epoch=10 step: 157762 loss 0.003322676 processed: [10.096768]
epoch=10 step: 159324 loss 0.0012830326 processed: [10.196736]
epoch=10 step: 160886 loss 0.036021553 processed: [10.296704]
epoch=10 step: 162448 loss 0.010286907 processed: [10.396672]
epoch=10 step: 164010 loss 0.0065174336 processed: [10.49664]
epoch=10 step: 165572 loss 0.004587262 processed: [10.596608]
epoch=10 step: 167134 loss 0.015853772 processed: [10.696576]
epoch=10 step: 168696 loss 0.032195408 processed: [10.796544]
epoch=10 step: 170258 loss 0.0015316649 processed: [10.896512]
epoch=10 step: 171820 loss 0.0020286115 processed: [10.99648]
total num: 665
MAP: 0.527477736054
MRR: 0.573036758563
P@1: 0.375939849624
('R10_1:', 0.22242988423439547)
('R10_2', 0.3958980785296575)
('R10_5', 0.7618140589569163)
('ave:', 0.4760993943270242)
save evaluate_step: 11
2018-11-23 21:23:32
learning rate: 4.6875e-05
0.01106585
epoch=10 save model
2018-11-23 21:23:33
train time:21.9410 h
