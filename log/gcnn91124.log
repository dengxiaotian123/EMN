nohup: 忽略输入
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
(?, 50, 800)
starting loading data
2018-11-24 17:41:11
finish loading data
2018-11-24 17:46:49
batch_num 15625
configurations {'keep_prob': 0.7, 'data_path': '../../data/ubuntu/data.pkl', 'word_layers_itg': 2, 'evaluate_step': 15625, 'filter_size': 2, 'filter_h': 3, 'hidden_embedding_dim': 200, 'emb_train': False, 'embedding_file': '../../data/ubuntu/word_embedding.pkl', 'CPU': '/cpu:0', 'epoch': 8, 'lr': 0.001, 'save_path': 'Gcnn_v9_test/version_1/', 'word_layers_enc': 2, 'print_step': 1562, '_EOS_': 28270, 'word_embedding_dim': 200, 'batch_size': 64, 'max_turn_num': 10, 'final_n_class': 1, 'word_layers_agg': 2, 'max_turn_len': 50, 'train_steps': 125000, 'output_path': 'Gcnn_v9_output/version_1/', 'init_model': 'Gcnn_v9_model/version_1/'}
2018-11-24 17:47:18.892192: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-24 17:47:18.892210: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-24 17:47:18.892214: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2018-11-24 17:47:18.892218: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2018-11-24 17:47:18.892221: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2018-11-24 17:47:19.006623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2018-11-24 17:47:19.007052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: GeForce GTX 1070
major: 6 minor: 1 memoryClockRate (GHz) 1.683
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.79GiB
2018-11-24 17:47:19.007063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2018-11-24 17:47:19.007068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2018-11-24 17:47:19.007074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
starting shuffle train data
finish building train data
2018-11-24 17:48:33.135423: W tensorflow/core/common_runtime/bfc_allocator.cc:217] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.78GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.
2018-11-24 17:48:33.218835: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1862 get requests, put_count=1286 evicted_count=1000 eviction_rate=0.777605 and unsatisfied allocation rate=0.900107
2018-11-24 17:48:33.218865: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
2018-11-24 17:48:37.350053: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1862 get requests, put_count=1388 evicted_count=1000 eviction_rate=0.720461 and unsatisfied allocation rate=0.800752
2018-11-24 17:48:37.350093: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 193 to 212
2018-11-24 17:48:41.596703: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1869 get requests, put_count=1588 evicted_count=1000 eviction_rate=0.629723 and unsatisfied allocation rate=0.70305
2018-11-24 17:48:41.596740: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 372 to 409
2018-11-24 17:48:47.307230: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1867 get requests, put_count=2126 evicted_count=1000 eviction_rate=0.470367 and unsatisfied allocation rate=0.439207
2018-11-24 17:48:47.307260: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 871 to 958
epoch=0 step: 1562 loss 0.39316213 processed: [0.099968]
epoch=0 step: 3124 loss 0.35751715 processed: [0.199936]
epoch=0 step: 4686 loss 0.28942102 processed: [0.299904]
epoch=0 step: 6248 loss 0.27761608 processed: [0.399872]
epoch=0 step: 7810 loss 0.26589924 processed: [0.49984]
epoch=0 step: 9372 loss 0.2445041 processed: [0.599808]
epoch=0 step: 10934 loss 0.2675693 processed: [0.699776]
epoch=0 step: 12496 loss 0.29164433 processed: [0.799744]
epoch=0 step: 14058 loss 0.334321 processed: [0.899712]
epoch=0 step: 15620 loss 0.45620662 processed: [0.99968]
('R10_1', 0.7480248814928896)
('R10_2', 0.8597715862951777)
('R10_5', 0.963217793067584)
('R2_1', 0.930875852551153)
save evaluate_step: 1
2018-11-24 20:55:58
starting shuffle train data
finish building train data
epoch=1 step: 17182 loss 0.26787588 processed: [1.099648]
epoch=1 step: 18744 loss 0.28872702 processed: [1.199616]
epoch=1 step: 20306 loss 0.3584042 processed: [1.299584]
epoch=1 step: 21868 loss 0.29097003 processed: [1.399552]
epoch=1 step: 23430 loss 0.29749435 processed: [1.49952]
epoch=1 step: 24992 loss 0.25185257 processed: [1.599488]
epoch=1 step: 26554 loss 0.38572317 processed: [1.699456]
epoch=1 step: 28116 loss 0.27951187 processed: [1.799424]
epoch=1 step: 29678 loss 0.23834386 processed: [1.899392]
epoch=1 step: 31240 loss 0.2183875 processed: [1.99936]
('R10_1', 0.758785527131628)
('R10_2', 0.8678720723243395)
('R10_5', 0.9659179550773046)
('R2_1', 0.9349360961657699)
save evaluate_step: 2
2018-11-25 00:05:10
0.32039833
epoch=2 save model
learnrate 0.001
2018-11-25 00:05:11
starting shuffle train data
finish building train data
epoch=2 step: 32802 loss 0.25379896 processed: [2.099328]
epoch=2 step: 34364 loss 0.26196915 processed: [2.199296]
epoch=2 step: 35926 loss 0.3420899 processed: [2.299264]
epoch=2 step: 37488 loss 0.22613916 processed: [2.399232]
epoch=2 step: 39050 loss 0.13313234 processed: [2.4992]
epoch=2 step: 40612 loss 0.19869784 processed: [2.599168]
epoch=2 step: 42174 loss 0.17127311 processed: [2.699136]
epoch=2 step: 43736 loss 0.27716854 processed: [2.799104]
epoch=2 step: 45298 loss 0.3154893 processed: [2.899072]
epoch=2 step: 46860 loss 0.27417603 processed: [2.99904]
('R10_1', 0.7607856471388283)
('R10_2', 0.8694921695301718)
('R10_5', 0.9668780126807609)
('R2_1', 0.93563613816829)
save evaluate_step: 3
2018-11-25 03:14:35
0.16834763
epoch=3 save model
learnrate 0.00075
2018-11-25 03:14:36
starting shuffle train data
finish building train data
epoch=3 step: 48422 loss 0.2831662 processed: [3.099008]
epoch=3 step: 49984 loss 0.1858282 processed: [3.198976]
epoch=3 step: 51546 loss 0.2603281 processed: [3.298944]
epoch=3 step: 53108 loss 0.21356925 processed: [3.398912]
epoch=3 step: 54670 loss 0.16508105 processed: [3.49888]
epoch=3 step: 56232 loss 0.30275849 processed: [3.598848]
epoch=3 step: 57794 loss 0.2670256 processed: [3.698816]
epoch=3 step: 59356 loss 0.2586127 processed: [3.798784]
epoch=3 step: 60918 loss 0.27361554 processed: [3.898752]
epoch=3 step: 62480 loss 0.15463813 processed: [3.99872]
('R10_1', 0.7514450867052023)
('R10_2', 0.8670520231213873)
('R10_5', 0.9663179790787447)
('R2_1', 0.9335360121607297)
save evaluate_step: 4
2018-11-25 06:23:38
0.24597386
epoch=4 save model
learnrate 0.00075
2018-11-25 06:23:40
starting shuffle train data
finish building train data
epoch=4 step: 64042 loss 0.21117386 processed: [4.098688]
epoch=4 step: 65604 loss 0.22284368 processed: [4.198656]
epoch=4 step: 67166 loss 0.19325735 processed: [4.298624]
epoch=4 step: 68728 loss 0.23089015 processed: [4.398592]
epoch=4 step: 70290 loss 0.098912135 processed: [4.49856]
epoch=4 step: 71852 loss 0.24747911 processed: [4.598528]
epoch=4 step: 73414 loss 0.15131745 processed: [4.698496]
epoch=4 step: 74976 loss 0.24529895 processed: [4.798464]
epoch=4 step: 76538 loss 0.14794739 processed: [4.898432]
epoch=4 step: 78100 loss 0.19872233 processed: [4.9984]
('R10_1', 0.7473848430905854)
('R10_2', 0.8643718623117387)
('R10_5', 0.9647178830729843)
('R2_1', 0.9340560433626017)
save evaluate_step: 5
2018-11-25 09:32:55
0.25334084
epoch=5 save model
learnrate 0.000375
2018-11-25 09:32:56
starting shuffle train data
finish building train data
epoch=5 step: 79662 loss 0.14161539 processed: [5.098368]
epoch=5 step: 81224 loss 0.1662554 processed: [5.198336]
epoch=5 step: 82786 loss 0.13270645 processed: [5.298304]
epoch=5 step: 84348 loss 0.14469647 processed: [5.398272]
epoch=5 step: 85910 loss 0.06472181 processed: [5.49824]
epoch=5 step: 87472 loss 0.1126686 processed: [5.598208]
epoch=5 step: 89034 loss 0.15388179 processed: [5.698176]
epoch=5 step: 90596 loss 0.17434344 processed: [5.798144]
epoch=5 step: 92158 loss 0.12654641 processed: [5.898112]
epoch=5 step: 93720 loss 0.13829497 processed: [5.99808]
('R10_1', 0.7374642478548713)
('R10_2', 0.8572114326859611)
('R10_5', 0.963257795467728)
('R2_1', 0.930555833350001)
save evaluate_step: 6
2018-11-25 12:44:06
0.14981191
epoch=6 save model
learnrate 0.000375
2018-11-25 12:44:08
starting shuffle train data
finish building train data
epoch=6 step: 95282 loss 0.08136156 processed: [6.098048]
epoch=6 step: 96844 loss 0.153348 processed: [6.198016]
epoch=6 step: 98406 loss 0.04736968 processed: [6.297984]
epoch=6 step: 99968 loss 0.17105918 processed: [6.397952]
epoch=6 step: 101530 loss 0.04421673 processed: [6.49792]
epoch=6 step: 103092 loss 0.13215649 processed: [6.597888]
epoch=6 step: 104654 loss 0.10714009 processed: [6.697856]
epoch=6 step: 106216 loss 0.094547994 processed: [6.797824]
epoch=6 step: 107778 loss 0.15394445 processed: [6.897792]
epoch=6 step: 109340 loss 0.055684015 processed: [6.99776]
('R10_1', 0.7201432085925156)
('R10_2', 0.8503310198611916)
('R10_5', 0.9605576334580075)
('R2_1', 0.926095565733944)
save evaluate_step: 7
2018-11-25 15:55:55
0.05675914
epoch=7 save model
learnrate 0.0001875
2018-11-25 15:55:57
starting shuffle train data
finish building train data
epoch=7 step: 110902 loss 0.06755953 processed: [7.097728]
epoch=7 step: 112464 loss 0.0932074 processed: [7.197696]
epoch=7 step: 114026 loss 0.02619476 processed: [7.297664]
epoch=7 step: 115588 loss 0.03157451 processed: [7.397632]
epoch=7 step: 117150 loss 0.14196573 processed: [7.4976]
epoch=7 step: 118712 loss 0.036121115 processed: [7.597568]
epoch=7 step: 120274 loss 0.04896362 processed: [7.697536]
epoch=7 step: 121836 loss 0.03362621 processed: [7.797504]
epoch=7 step: 123398 loss 0.15230563 processed: [7.897472]
epoch=7 step: 124960 loss 0.04136376 processed: [7.99744]
('R10_1', 0.7101426085565133)
('R10_2', 0.8448706922415344)
('R10_5', 0.9577974678480708)
('R2_1', 0.9223353401204072)
save evaluate_step: 8
2018-11-25 19:06:36
0.12291491
epoch=8 save model
learnrate 0.0001875
2018-11-25 19:06:37
train time:25.4240 h
